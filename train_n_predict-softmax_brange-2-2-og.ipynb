{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "brightness_range = [-60, 150]\n",
    "contrast_range =  [0.5,2]\n",
    "\n",
    "x = np.random.randint(0, 2)\n",
    "def get_image_slices(img):\n",
    "    \n",
    "    dim = 2560\n",
    "    imgs = np.zeros([4,640,640,3])\n",
    "    imgs[0] = img[0:int(dim/4), 0:int(dim/4), :]\n",
    "    imgs[1] = img[int(dim/4):int(dim/2), int(dim/4):int(dim/2), :]\n",
    "    imgs[2] = img[int(dim/2):int(3*dim/4), int(dim/2):int(3*dim/4), :]\n",
    "    imgs[3] = img[int(3*dim/4):int(dim), int(3*dim/4):int(dim), :]\n",
    "    \n",
    "    return np.asarray(imgs)\n",
    "\n",
    "def contrast_n_brightness(img_path, c_range=[0.5,2], b_range=[-50, 150]):\n",
    "    img = load_img(img_path)\n",
    "    def rand_generator(min= -2, max = 10):\n",
    "        n = (max-min)*np.random.random()+min\n",
    "        return n\n",
    "    x = np.random.randint(0, 2)\n",
    "    if x ==1:\n",
    "        contrast = rand_generator(c_range[0], c_range[1])\n",
    "        brightness = 0\n",
    "        \n",
    "    else:\n",
    "        contrast = 1\n",
    "        brightness = rand_generator(b_range[0], b_range[1])\n",
    "    img = np.multiply(img, contrast)+brightness\n",
    "    img = np.clip(img, 0, 255)\n",
    "    img = img/255\n",
    "    img = get_image_slices(img)\n",
    "    return img\n",
    "\n",
    "def load_img(path, norm = False):\n",
    "    if norm:\n",
    "        img =  cv2.imread(path)/255\n",
    "    else: \n",
    "        img = cv2.imread(path)\n",
    "    return img\n",
    "def my_data_gen(in_paths, out_paths, batch_size=32, img_dim = [640,640]):\n",
    "    \n",
    "    \n",
    "    #print(len(img_paths))\n",
    "    #print(img_paths.shape)\n",
    "    real_batch_Size = int(batch_size/4)\n",
    "\n",
    "    while True:\n",
    "        select_from = range(len(in_paths))\n",
    "        indices = np.random.choice(a=select_from, size = (real_batch_Size))\n",
    "    \n",
    "        in_paths = np.asarray(in_paths)\n",
    "        out_paths = np.asarray(out_paths)\n",
    "    \n",
    "        img_paths = in_paths[indices]\n",
    "        label_paths = out_paths[indices]\n",
    "    \n",
    "        loaded_imgs = np.zeros([0, 640, 640,1])\n",
    "        loaded_labels = np.zeros([0, 640, 640, 2])\n",
    "        for i in range(real_batch_Size):\n",
    "            #print(i)\n",
    "            img_temp = contrast_n_brightness(img_paths[i])\n",
    "            img_temp = img_temp[:, :, :, 0]\n",
    "            img_temp = img_temp.reshape(4, 640, 640, 1)\n",
    "            lbl_temp = load_img(label_paths[i], norm = True)\n",
    "            lbl_temp = get_image_slices(lbl_temp)\n",
    "            lbl_temp = lbl_temp[:, :, :, 0:2]\n",
    "            loaded_imgs = np.vstack([loaded_imgs, img_temp])\n",
    "            loaded_labels = np.vstack([loaded_labels, lbl_temp])\n",
    "        yield (loaded_imgs, loaded_labels)\n",
    "#test = my_data_gen(training_img_paths[\"x\"], training_img_paths[\"y\"], batch_size=32)\n",
    "#print(test[0].shape)\n",
    "#plt.imshow(test[0][0, :, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting some default values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of images found is 3000 and the number of labels is 3000\n"
     ]
    }
   ],
   "source": [
    "img_lib = \"x\"\n",
    "lab_lib = \"y\"\n",
    "\n",
    "num_training_images = 2600\n",
    "training_start_index = 0\n",
    "training_end_index = training_start_index+num_training_images\n",
    "\n",
    "test_starting_index = 2800\n",
    "num_test_images = 50\n",
    "test_end_index = test_starting_index+num_test_images\n",
    "\n",
    "img_paths = glob.glob(img_lib+\"/*.png\")\n",
    "lab_paths = glob.glob(lab_lib+\"/*.png\")\n",
    "\n",
    "img_num = len(img_paths)\n",
    "lab_num = len(lab_paths)\n",
    "message = \"The number of images found is {0:4d} and the number of labels is {1:4d}\".format(img_num, lab_num)\n",
    "print(message)\n",
    "\n",
    "#ensuring that they are in the same order:\n",
    "\n",
    "img_paths.sort()\n",
    "lab_paths.sort()\n",
    "\n",
    "#creating the dictionary with the selected slices of paths\n",
    "\n",
    "training_img_paths = {\"x\": img_paths[training_start_index:training_end_index], \"y\": lab_paths[training_start_index:training_end_index]}\n",
    "test_img_paths = {\"x\": img_paths[test_starting_index:test_end_index], \"y\": lab_paths[test_starting_index:test_end_index]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loading_helpers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tesing whether the images and labels match..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visual_test_n_loaded_imgs(5, ready_im, ready_lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0723 18:41:28.326976 140070506657152 deprecation_wrapper.py:119] From /home/contact_gergo_endresz/j/get_unet.py:2: The name tf.keras.layers.CuDNNGRU is deprecated. Please use tf.compat.v1.keras.layers.CuDNNGRU instead.\n",
      "\n",
      "W0723 18:41:28.328938 140070506657152 deprecation_wrapper.py:119] From /home/contact_gergo_endresz/j/get_unet.py:2: The name tf.keras.layers.CuDNNLSTM is deprecated. Please use tf.compat.v1.keras.layers.CuDNNLSTM instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0723 18:41:29.259582 140070506657152 deprecation.py:506] From /home/contact_gergo_endresz/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "from get_unet import *\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras import losses\n",
    "input_img = Input((640,640,1))\n",
    "model = get_unet(input_img, n_filters = 16, dropout = 0.5, batchnorm=True, passed_activation = \"softmax\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_loss = losses.binary_crossentropy\n",
    "\n",
    "model.compile(\"adam\", loss=selected_loss, metrics=[\"accuracy\", losses.mean_squared_error, losses.logcosh, losses.kullback_leibler_divergence,  losses.binary_crossentropy, losses.mean_squared_logarithmic_error])\n",
    "\n",
    "#model.load_weights(\"./ckpts/2d_sigm_norm.hdf5\")\n",
    "\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\"./ckpts/sm_own_gen_1.hdf5\", save_best=1, monitor=\"val_loss\", mode=\"auto\")\n",
    "tboard = tf.keras.callbacks.TensorBoard(\"./ckpts/tb5/\", histogram_freq=1, batch_size=20, write_graph = False, write_grads = False, write_images = True, update_freq = \"epoch\")\n",
    "callbacks = [checkpoint, tboard]\n",
    "\n",
    "#datagen = tf.keras.preprocessing.image.ImageDataGenerator(validation_split=0.2, brightness_range=[0.3, 2])#,\n",
    "                               #rotation_range=15,\n",
    "                               #width_shift_range=0.1,\n",
    "                               #height_shift_range=0.1,\n",
    "                               #shear_range=0.01,\n",
    "                               #zoom_range=[0.5, 1.25],\n",
    "                               #horizontal_flip=True,\n",
    "                               #vertical_flip=True,\n",
    "                               #fill_mode='reflect',\n",
    "                               #rotation_range=360, fill_mode = \"reflect\", horizontal_flip=1, vertical_flip=1,)\n",
    "#datagen = tf.keras.preprocessing.image.ImageDataGenerator(featurewise_std_normalization= 1, rotation_range=360, fill_mode = \"reflect\", horizontal_flip=1, vertical_flip=1, validation_split=0.2)\n",
    "#you have to use datagen.fit if u want to use featurewise_std_normalization so that the generator learns about the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0723 18:41:34.004420 140070506657152 deprecation.py:323] From /home/contact_gergo_endresz/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 485s 49s/step - loss: 0.7507 - acc: 0.5476 - mean_squared_error: 0.2683 - logcosh: 0.1261 - kullback_leibler_divergence: 0.0815 - binary_crossentropy: 0.7507 - mean_squared_logarithmic_error: 0.1605\n",
      "Epoch 2/100\n",
      "10/10 [==============================] - 472s 47s/step - loss: 0.6967 - acc: 0.5531 - mean_squared_error: 0.2499 - logcosh: 0.1194 - kullback_leibler_divergence: 0.0915 - binary_crossentropy: 0.6967 - mean_squared_logarithmic_error: 0.1562\n",
      "Epoch 3/100\n",
      "10/10 [==============================] - 475s 48s/step - loss: 0.6850 - acc: 0.5580 - mean_squared_error: 0.2455 - logcosh: 0.1176 - kullback_leibler_divergence: 0.0909 - binary_crossentropy: 0.6850 - mean_squared_logarithmic_error: 0.1550\n",
      "Epoch 4/100\n",
      "10/10 [==============================] - 473s 47s/step - loss: 0.6799 - acc: 0.5634 - mean_squared_error: 0.2434 - logcosh: 0.1166 - kullback_leibler_divergence: 0.0841 - binary_crossentropy: 0.6799 - mean_squared_logarithmic_error: 0.1541\n",
      "Epoch 5/100\n",
      "10/10 [==============================] - 475s 48s/step - loss: 0.6760 - acc: 0.5651 - mean_squared_error: 0.2417 - logcosh: 0.1158 - kullback_leibler_divergence: 0.0785 - binary_crossentropy: 0.6760 - mean_squared_logarithmic_error: 0.1530\n",
      "Epoch 6/100\n",
      "10/10 [==============================] - 473s 47s/step - loss: 0.6719 - acc: 0.5668 - mean_squared_error: 0.2401 - logcosh: 0.1150 - kullback_leibler_divergence: 0.0769 - binary_crossentropy: 0.6719 - mean_squared_logarithmic_error: 0.1522\n",
      "Epoch 7/100\n",
      "10/10 [==============================] - 476s 48s/step - loss: 0.6693 - acc: 0.5640 - mean_squared_error: 0.2391 - logcosh: 0.1145 - kullback_leibler_divergence: 0.0707 - binary_crossentropy: 0.6693 - mean_squared_logarithmic_error: 0.1517\n",
      "Epoch 8/100\n",
      "10/10 [==============================] - 474s 47s/step - loss: 0.6670 - acc: 0.5657 - mean_squared_error: 0.2381 - logcosh: 0.1140 - kullback_leibler_divergence: 0.0701 - binary_crossentropy: 0.6670 - mean_squared_logarithmic_error: 0.1513\n",
      "Epoch 9/100\n",
      "10/10 [==============================] - 473s 47s/step - loss: 0.6623 - acc: 0.5675 - mean_squared_error: 0.2360 - logcosh: 0.1130 - kullback_leibler_divergence: 0.0658 - binary_crossentropy: 0.6623 - mean_squared_logarithmic_error: 0.1501\n",
      "Epoch 10/100\n",
      "10/10 [==============================] - 474s 47s/step - loss: 0.6602 - acc: 0.5671 - mean_squared_error: 0.2352 - logcosh: 0.1126 - kullback_leibler_divergence: 0.0629 - binary_crossentropy: 0.6602 - mean_squared_logarithmic_error: 0.1496\n",
      "Epoch 11/100\n",
      "10/10 [==============================] - 474s 47s/step - loss: 0.6604 - acc: 0.5662 - mean_squared_error: 0.2353 - logcosh: 0.1126 - kullback_leibler_divergence: 0.0620 - binary_crossentropy: 0.6604 - mean_squared_logarithmic_error: 0.1497\n",
      "Epoch 12/100\n",
      "10/10 [==============================] - 473s 47s/step - loss: 0.6564 - acc: 0.5673 - mean_squared_error: 0.2337 - logcosh: 0.1118 - kullback_leibler_divergence: 0.0584 - binary_crossentropy: 0.6564 - mean_squared_logarithmic_error: 0.1489\n",
      "Epoch 13/100\n",
      "10/10 [==============================] - 474s 47s/step - loss: 0.6543 - acc: 0.5665 - mean_squared_error: 0.2329 - logcosh: 0.1115 - kullback_leibler_divergence: 0.0562 - binary_crossentropy: 0.6543 - mean_squared_logarithmic_error: 0.1487\n",
      "Epoch 14/100\n",
      "10/10 [==============================] - 475s 47s/step - loss: 0.6512 - acc: 0.5675 - mean_squared_error: 0.2317 - logcosh: 0.1109 - kullback_leibler_divergence: 0.0539 - binary_crossentropy: 0.6512 - mean_squared_logarithmic_error: 0.1480\n",
      "Epoch 15/100\n",
      "10/10 [==============================] - 475s 47s/step - loss: 0.6483 - acc: 0.5684 - mean_squared_error: 0.2307 - logcosh: 0.1105 - kullback_leibler_divergence: 0.0520 - binary_crossentropy: 0.6483 - mean_squared_logarithmic_error: 0.1475\n",
      "Epoch 16/100\n",
      "10/10 [==============================] - 472s 47s/step - loss: 0.6457 - acc: 0.5688 - mean_squared_error: 0.2298 - logcosh: 0.1100 - kullback_leibler_divergence: 0.0498 - binary_crossentropy: 0.6457 - mean_squared_logarithmic_error: 0.1471\n",
      "Epoch 17/100\n",
      "10/10 [==============================] - 471s 47s/step - loss: 0.6467 - acc: 0.5679 - mean_squared_error: 0.2303 - logcosh: 0.1103 - kullback_leibler_divergence: 0.0493 - binary_crossentropy: 0.6467 - mean_squared_logarithmic_error: 0.1474\n",
      "Epoch 18/100\n",
      "10/10 [==============================] - 475s 47s/step - loss: 0.6440 - acc: 0.5693 - mean_squared_error: 0.2293 - logcosh: 0.1098 - kullback_leibler_divergence: 0.0469 - binary_crossentropy: 0.6440 - mean_squared_logarithmic_error: 0.1469\n",
      "Epoch 19/100\n",
      "10/10 [==============================] - 472s 47s/step - loss: 0.6410 - acc: 0.5691 - mean_squared_error: 0.2283 - logcosh: 0.1094 - kullback_leibler_divergence: 0.0439 - binary_crossentropy: 0.6410 - mean_squared_logarithmic_error: 0.1466\n",
      "Epoch 20/100\n",
      "10/10 [==============================] - 475s 48s/step - loss: 0.6374 - acc: 0.5713 - mean_squared_error: 0.2270 - logcosh: 0.1087 - kullback_leibler_divergence: 0.0433 - binary_crossentropy: 0.6374 - mean_squared_logarithmic_error: 0.1457\n",
      "Epoch 21/100\n",
      " 8/10 [=======================>......] - ETA: 1:34 - loss: 0.6381 - acc: 0.5697 - mean_squared_error: 0.2274 - logcosh: 0.1089 - kullback_leibler_divergence: 0.0419 - binary_crossentropy: 0.6381 - mean_squared_logarithmic_error: 0.1461"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/api/_v1/keras/layers/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m model.fit_generator( my_data_gen(training_img_paths[\"x\"], training_img_paths[\"y\"], batch_size=12), \n\u001b[0;32m----> 2\u001b[0;31m                               epochs = 100, steps_per_epoch = 10, verbose = True, callbacks = callbacks)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1431\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1432\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1433\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m   1434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1435\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m       \u001b[0mis_deferred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m       \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1173\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_sample_weight_modes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1174\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1175\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3292\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit_generator( my_data_gen(training_img_paths[\"x\"], training_img_paths[\"y\"], batch_size=12), \n",
    "                              epochs = 100, steps_per_epoch = 10, verbose = True, callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_im, pred_lab = load_imgs_parallel(test_img_paths, num_slices=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(x=ready_im, batch_size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visual_test_n_preds(5, ready_lab, preds, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
