{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 100)\n",
      "(100, 2)\n",
      "x/frame_0001.png\n",
      "y/frame_0001.png\n"
     ]
    }
   ],
   "source": [
    "base_dir =\"./rec1_processed\"\n",
    "img_dir = os.path.join(\"x\",\"*.png\")\n",
    "#print(img_dir) \n",
    "lab_dir = os.path.join(\"y\", \"*.png\")\n",
    "\n",
    "num_images =100\n",
    "\n",
    "imgs = glob.glob(img_dir)\n",
    "labs = glob.glob(lab_dir)\n",
    "imgs.sort()\n",
    "labs.sort()\n",
    "\n",
    "imgs=imgs[0:num_images]\n",
    "labs = labs[0:num_images]\n",
    "training_paths = [imgs, labs]\n",
    "training_paths = np.asarray(training_paths)\n",
    "print(training_paths.shape)\n",
    "training_paths = training_paths.T\n",
    "print(training_paths.shape)\n",
    "\n",
    "\n",
    "print(training_paths[0][0])\n",
    "print(training_paths[0][1])\n",
    "\n",
    "#print(labs[0])\n",
    "#print(imgs[0])\n",
    "\n",
    "training_paths = [imgs, labs]\n",
    "\n",
    "\n",
    "def get_image_slices(img, label=False):\n",
    "    \n",
    "    dim = 2560\n",
    "    imgs = np.empty([4, 640, 640, 3])\n",
    "    imgs[0] = img[0:int(dim/4), 0:int(dim/4), :]\n",
    "    imgs[1] = img[int(dim/4):int(dim/2), int(dim/4):int(dim/2), :]\n",
    "    imgs[2] = img[int(dim/2):int(3*dim/4), int(dim/2):int(3*dim/4), :]\n",
    "    imgs[3] = img[int(3*dim/4):int(dim), int(3*dim/4):int(dim), :]\n",
    "\n",
    "    return np.asarray(imgs)\n",
    "\n",
    "def get_training_set(img):\n",
    "    raw_img = cv2.imread(img[0])\n",
    "    raw_label = cv2.imread(img[1])\n",
    "  \n",
    "    imgs = get_image_slices(raw_img)\n",
    "    labels = get_image_slices(raw_label, True)\n",
    "  \n",
    "    return imgs, labels\n",
    "training_paths = np.asarray(training_paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 640, 640, 3)\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread(\"x/frame_0001.png\")\n",
    "arr = [\"x/frame_0001.png\", \"y/frame_0001.png\"]\n",
    "#img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "img, label = get_training_set(arr)\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training paths    2\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'int' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-51b38aabcceb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training paths %4d\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mslices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_paths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mslice_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'int' has no len()"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "import time\n",
    "\n",
    "\n",
    "slice_num = 10\n",
    "\n",
    "pool = mp.Pool(mp.cpu_count())\n",
    "\n",
    "print(\"Training paths %4d\"%(len(training_paths)))\n",
    "\n",
    "slices = int(len(training_paths.shape[0])/slice_num)\n",
    "\n",
    "print(slices)\n",
    "start_time = time.time()\n",
    "res = np.array([])\n",
    "imgs_ready = np.empty([0, 640, 640]) \n",
    "labels_ready = np.empty([0, 640, 640, 2]) \n",
    "\n",
    "for i in range(1):\n",
    "    slice_start = time.time()\n",
    "    print(\"%d. slice has been started being loaded.\"%(i+1))\n",
    "    \n",
    "    cur_slice = training_paths[int(i*slices):int((i+1)*slices)]\n",
    "    \n",
    "    print(\"The current slize's shape is: \")\n",
    "    print(np.asarray(cur_slice).shape)\n",
    "    x = [pool.map(get_training_set, [img_pair for img_pair in cur_slice])]\n",
    "    \n",
    "    x = np.asarray(x)\n",
    "    print(\"The loaded images' shape is:\")\n",
    "    print(x.shape)\n",
    "    x = x.reshape(2, 4*slices, 640, 640, 3)\n",
    "    print(x.shape)\n",
    "    slice_end = time.time()\n",
    "    took = (slice_end-slice_start)\n",
    "    print(\"{0:1d}. slice has finished in {1:10.5f} seconds.\".format((i+1), took))\n",
    "    im_temp = x[0, :, :, :, 0]\n",
    "    print(im_temp.shape)\n",
    "    lab_temp = x[1, :, :, :, 0:2]\n",
    "    print(lab_temp.shape)\n",
    "    imgs_ready = np.vstack((imgs_ready, im_temp))\n",
    "    labels_ready = np.vstack((labels_ready, lab_temp))\n",
    "    \n",
    "end_time = time.time()\n",
    "full_took = end_time - start_time\n",
    "print(\"Total time: {0:10.5f} seconds\".format(full_took))\n",
    "pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras import losses\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(labels_ready[0, :, :, 0], cmap= \"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d_block(input_tensor, n_filters, kernel_size=3, batchnorm=True):\n",
    "    # first layer\n",
    "    x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), kernel_initializer=\"he_normal\",\n",
    "               padding=\"same\")(input_tensor)\n",
    "    if batchnorm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    # second layer\n",
    "    x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), kernel_initializer=\"he_normal\",\n",
    "               padding=\"same\")(x)\n",
    "    if batchnorm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    return x\n",
    "\n",
    "def get_unet(input_img, n_filters=16, dropout=0.5, batchnorm=True):\n",
    "    # contracting path\n",
    "    c1 = conv2d_block(input_img, n_filters=n_filters*1, kernel_size=3, batchnorm=batchnorm)\n",
    "    p1 = MaxPooling2D((2, 2)) (c1)\n",
    "    p1 = Dropout(dropout*0.5)(p1)\n",
    "\n",
    "    c2 = conv2d_block(p1, n_filters=n_filters*2, kernel_size=3, batchnorm=batchnorm)\n",
    "    p2 = MaxPooling2D((2, 2)) (c2)\n",
    "    p2 = Dropout(dropout)(p2)\n",
    "\n",
    "    c3 = conv2d_block(p2, n_filters=n_filters*4, kernel_size=3, batchnorm=batchnorm)\n",
    "    p3 = MaxPooling2D((2, 2)) (c3)\n",
    "    p3 = Dropout(dropout)(p3)\n",
    "\n",
    "    c4 = conv2d_block(p3, n_filters=n_filters*8, kernel_size=3, batchnorm=batchnorm)\n",
    "    p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n",
    "    p4 = Dropout(dropout)(p4)\n",
    "    \n",
    "    c5 = conv2d_block(p4, n_filters=n_filters*16, kernel_size=3, batchnorm=batchnorm)\n",
    "    \n",
    "    # expansive path\n",
    "    u6 = Conv2DTranspose(n_filters*8, (3, 3), strides=(2, 2), padding='same') (c5)\n",
    "    u6 = concatenate([u6, c4])\n",
    "    u6 = Dropout(dropout)(u6)\n",
    "    c6 = conv2d_block(u6, n_filters=n_filters*8, kernel_size=3, batchnorm=batchnorm)\n",
    "\n",
    "    u7 = Conv2DTranspose(n_filters*4, (3, 3), strides=(2, 2), padding='same') (c6)\n",
    "    u7 = concatenate([u7, c3])\n",
    "    u7 = Dropout(dropout)(u7)\n",
    "    c7 = conv2d_block(u7, n_filters=n_filters*4, kernel_size=3, batchnorm=batchnorm)\n",
    "\n",
    "    u8 = Conv2DTranspose(n_filters*2, (3, 3), strides=(2, 2), padding='same') (c7)\n",
    "    u8 = concatenate([u8, c2])\n",
    "    u8 = Dropout(dropout)(u8)\n",
    "    c8 = conv2d_block(u8, n_filters=n_filters*2, kernel_size=3, batchnorm=batchnorm)\n",
    "\n",
    "    u9 = Conv2DTranspose(n_filters*1, (3, 3), strides=(2, 2), padding='same') (c8)\n",
    "    u9 = concatenate([u9, c1], axis=3)\n",
    "    u9 = Dropout(dropout)(u9)\n",
    "    c9 = conv2d_block(u9, n_filters=n_filters*1, kernel_size=3, batchnorm=batchnorm)\n",
    "    \n",
    "    outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)\n",
    "    model = Model(inputs=[input_img], outputs=[outputs])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = Input((640, 640, 1), name='img')\n",
    "model = get_unet(input_img, n_filters=16, dropout=0.5, batchnorm=True)\n",
    "model.load_weights(\"./ckpts/tb4/best_1.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "selected_loss = \"binary_crossentropy\"\n",
    "model.compile(\"adam\", loss=selected_loss, metrics=[\"accuracy\", losses.mean_squared_error, losses.logcosh, losses.kullback_leibler_divergence,  losses.binary_crossentropy, losses.mean_squared_logarithmic_error])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\"./ckpts/un/50_10_10ep_best.hdf5\", save_best=1, monitor=\"val_loss\", mode=\"auto\")\n",
    "tboard = tf.keras.callbacks.TensorBoard(\"./ckpts/un/50\", histogram_freq=1, batch_size=10, write_graph = True, write_grads = True, write_images = True, update_freq = \"batch\")\n",
    "callbacks = [checkpoint, tboard]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(validation_split=0.2,\n",
    "                               rotation_range=15,\n",
    "                               width_shift_range=0.1,\n",
    "                               height_shift_range=0.1,\n",
    "                               shear_range=0.01,\n",
    "                               zoom_range=[0.5, 1.25],\n",
    "                               horizontal_flip=True,\n",
    "                               vertical_flip=True,\n",
    "                               fill_mode='reflect',\n",
    "                               brightness_range=[0.5, 1.5])#rotation_range=360, fill_mode = \"reflect\", horizontal_flip=1, vertical_flip=1,)\n",
    "#datagen = tf.keras.preprocessing.image.ImageDataGenerator(featurewise_std_normalization= 1, rotation_range=360, fill_mode = \"reflect\", horizontal_flip=1, vertical_flip=1, validation_split=0.2)\n",
    "#you have to use datagen.fit if u want to use featurewise_std_normalization so that the generator learns about the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit_generator(datagen.flow(x=imgs_ready.reshape(1600,640,640,1), y=labels_ready.reshape(1600,640,640,1), batch_size=10, shuffle=True), steps_per_epoch = 10, epochs = 50, verbose = True, callbacks = callbacks, use_multiprocessing = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(loaded_imgs, batch_size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig = plt.Figure(figsize=(15,15))\n",
    "#grids = ImageGrid(fig, 111, nrows_ncols=(2,2))\n",
    "\n",
    "fig = plt.figure(figsize=(20,100))\n",
    "#nrows, ncols, and index \n",
    "grids = ImageGrid(fig, 111,  # similar to subplot(111)\n",
    "                 nrows_ncols=(10, 2),  # creates 2x2 grid of axes\n",
    "                 axes_pad=0.1,  # pad between axes in inch.\n",
    "                 )\n",
    "z = 0\n",
    "for i in range(10):  \n",
    "    test_im=preds[i]\n",
    "    original = loaded_imgs[i].reshape((640,640))\n",
    "    test_im = test_im*255\n",
    "    test_im = test_im.reshape((640,640))\n",
    "    test_im = test_im.astype(int)\n",
    "    z = 2*i\n",
    "    #print(test_im)  \n",
    "    grid1 = grids[z]\n",
    "    \n",
    "    grid2 = grids[z+1]\n",
    "    \n",
    "    grid1.imshow(original, cmap=\"gray\")\n",
    "    grid2.imshow(test_im, cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(\"promising_results.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
