{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "brightness_range = [-60, 150]\n",
    "contrast_range =  [0.5,2]\n",
    "\n",
    "x = np.random.randint(0, 2)\n",
    "def get_image_slices(img):\n",
    "    \n",
    "    dim = 2560\n",
    "    imgs = np.zeros([4,640,640,3])\n",
    "    imgs[0] = img[0:int(dim/4), 0:int(dim/4), :]\n",
    "    imgs[1] = img[int(dim/4):int(dim/2), int(dim/4):int(dim/2), :]\n",
    "    imgs[2] = img[int(dim/2):int(3*dim/4), int(dim/2):int(3*dim/4), :]\n",
    "    imgs[3] = img[int(3*dim/4):int(dim), int(3*dim/4):int(dim), :]\n",
    "    \n",
    "    return np.asarray(imgs)\n",
    "\n",
    "def contrast_n_brightness(img_path, c_range=[0.5,2], b_range=[-60, 150]):\n",
    "    img = load_img(img_path)\n",
    "    def rand_generator(min= -2, max = 10):\n",
    "        n = (max-min)*np.random.random()+min\n",
    "        return n\n",
    "    x = np.random.randint(0, 2)\n",
    "    if x ==1:\n",
    "        contrast = rand_generator(c_range[0], c_range[1])\n",
    "        brightness = 0\n",
    "        \n",
    "    else:\n",
    "        contrast = 1\n",
    "        brightness = rand_generator(b_range[0], b_range[1])\n",
    "    img = np.multiply(img, contrast)+brightness\n",
    "    img = np.clip(img, 0, 255)\n",
    "    img = img/255\n",
    "    img = get_image_slices(img)\n",
    "    return img\n",
    "\n",
    "def load_img(path, norm = False):\n",
    "    if norm:\n",
    "        img =  cv2.imread(path)/255\n",
    "    else: \n",
    "        img = cv2.imread(path)\n",
    "    return img\n",
    "def my_data_gen(in_paths, out_paths, batch_size=32, img_dim = [640,640]):\n",
    "    \n",
    "    \n",
    "    #print(len(img_paths))\n",
    "    #print(img_paths.shape)\n",
    "    real_batch_Size = int(batch_size/4)\n",
    "\n",
    "    while True:\n",
    "        select_from = range(len(in_paths))\n",
    "        indices = np.random.choice(a=select_from, size = (real_batch_Size))\n",
    "    \n",
    "        in_paths = np.asarray(in_paths)\n",
    "        out_paths = np.asarray(out_paths)\n",
    "    \n",
    "        img_paths = in_paths[indices]\n",
    "        label_paths = out_paths[indices]\n",
    "    \n",
    "        loaded_imgs = np.zeros([0, 640, 640,1])\n",
    "        loaded_labels = np.zeros([0, 640, 640, 2])\n",
    "        for i in range(real_batch_Size):\n",
    "            img_temp = contrast_n_brightness(img_paths[i])\n",
    "            img_temp = img_temp[:, :, :, 0]\n",
    "            img_temp = img_temp.reshape(4, 640, 640, 1)\n",
    "            lbl_temp = load_img(label_paths[i], norm = True)\n",
    "            lbl_temp = get_image_slices(lbl_temp)\n",
    "            lbl_temp = lbl_temp[:, :, :, 0:2]\n",
    "            loaded_imgs = np.vstack([loaded_imgs, img_temp])\n",
    "            loaded_labels = np.vstack([loaded_labels, lbl_temp])\n",
    "        #print(\"Batch loaded!\")\n",
    "        yield (loaded_imgs, loaded_labels)\n",
    "#test = my_data_gen(training_img_paths[\"x\"], training_img_paths[\"y\"], batch_size=32)\n",
    "#print(test[0].shape)\n",
    "#plt.imshow(test[0][0, :, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting some default values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of images found is 3000 and the number of labels is 3000\n"
     ]
    }
   ],
   "source": [
    "img_lib = \"x\"\n",
    "lab_lib = \"y\"\n",
    "\n",
    "num_training_images = 2600\n",
    "training_start_index = 0\n",
    "training_end_index = training_start_index+num_training_images\n",
    "\n",
    "test_starting_index = 2800\n",
    "num_test_images = 50\n",
    "test_end_index = test_starting_index+num_test_images\n",
    "\n",
    "img_paths = glob.glob(img_lib+\"/*.png\")\n",
    "lab_paths = glob.glob(lab_lib+\"/*.png\")\n",
    "\n",
    "img_num = len(img_paths)\n",
    "lab_num = len(lab_paths)\n",
    "message = \"The number of images found is {0:4d} and the number of labels is {1:4d}\".format(img_num, lab_num)\n",
    "print(message)\n",
    "\n",
    "#ensuring that they are in the same order:\n",
    "\n",
    "img_paths.sort()\n",
    "lab_paths.sort()\n",
    "\n",
    "#creating the dictionary with the selected slices of paths\n",
    "\n",
    "training_img_paths = {\"x\": img_paths[training_start_index:training_end_index], \"y\": lab_paths[training_start_index:training_end_index]}\n",
    "test_img_paths = {\"x\": img_paths[test_starting_index:test_end_index], \"y\": lab_paths[test_starting_index:test_end_index]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loading_helpers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tesing whether the images and labels match..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visual_test_n_loaded_imgs(5, ready_im, ready_lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0723 18:41:58.217692 140574328563072 deprecation_wrapper.py:119] From /home/contact_gergo_endresz/j/get_unet.py:2: The name tf.keras.layers.CuDNNGRU is deprecated. Please use tf.compat.v1.keras.layers.CuDNNGRU instead.\n",
      "\n",
      "W0723 18:41:58.219988 140574328563072 deprecation_wrapper.py:119] From /home/contact_gergo_endresz/j/get_unet.py:2: The name tf.keras.layers.CuDNNLSTM is deprecated. Please use tf.compat.v1.keras.layers.CuDNNLSTM instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0723 18:41:59.567105 140574328563072 deprecation.py:506] From /home/contact_gergo_endresz/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "from get_unet import *\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras import losses\n",
    "input_img = Input((640,640,1))\n",
    "model = get_unet(input_img, n_filters = 16, dropout = 0.5, batchnorm=True, passed_activation = \"sigmoid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0723 18:42:03.662505 140574328563072 deprecation.py:323] From /home/contact_gergo_endresz/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "selected_loss = losses.binary_crossentropy\n",
    "\n",
    "model.compile(\"adam\", loss=selected_loss, metrics=[\"accuracy\", losses.mean_squared_error, losses.logcosh, losses.kullback_leibler_divergence,  losses.binary_crossentropy, losses.mean_squared_logarithmic_error])\n",
    "\n",
    "#model.load_weights(\"./ckpts/2d_sigm_norm.hdf5\")\n",
    "\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\"./ckpts/sig_own_gen_1.hdf5\", save_best=1, monitor=\"val_loss\", mode=\"auto\")\n",
    "tboard = tf.keras.callbacks.TensorBoard(\"./ckpts/tb6/\", histogram_freq=1, batch_size=20, write_graph = False, write_grads = False, write_images = True, update_freq = \"epoch\")\n",
    "callbacks = [checkpoint, tboard]\n",
    "\n",
    "#datagen = tf.keras.preprocessing.image.ImageDataGenerator(validation_split=0.2, brightness_range=[0.3, 2])#,\n",
    "                               #rotation_range=15,\n",
    "                               #width_shift_range=0.1,\n",
    "                               #height_shift_range=0.1,\n",
    "                               #shear_range=0.01,\n",
    "                               #zoom_range=[0.5, 1.25],\n",
    "                               #horizontal_flip=True,\n",
    "                               #vertical_flip=True,\n",
    "                               #fill_mode='reflect',\n",
    "                               #rotation_range=360, fill_mode = \"reflect\", horizontal_flip=1, vertical_flip=1,)\n",
    "#datagen = tf.keras.preprocessing.image.ImageDataGenerator(featurewise_std_normalization= 1, rotation_range=360, fill_mode = \"reflect\", horizontal_flip=1, vertical_flip=1, validation_split=0.2)\n",
    "#you have to use datagen.fit if u want to use featurewise_std_normalization so that the generator learns about the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "10/10 [==============================] - 493s 49s/step - loss: 0.7782 - acc: 0.4844 - mean_squared_error: 0.2810 - logcosh: 0.1325 - kullback_leibler_divergence: 0.0810 - binary_crossentropy: 0.7782 - mean_squared_logarithmic_error: 0.1696\n",
      "Epoch 2/100\n",
      "10/10 [==============================] - 474s 47s/step - loss: 0.6286 - acc: 0.6708 - mean_squared_error: 0.2133 - logcosh: 0.1021 - kullback_leibler_divergence: 0.0937 - binary_crossentropy: 0.6286 - mean_squared_logarithmic_error: 0.1349\n",
      "Epoch 3/100\n",
      "10/10 [==============================] - 475s 47s/step - loss: 0.5381 - acc: 0.7667 - mean_squared_error: 0.1728 - logcosh: 0.0832 - kullback_leibler_divergence: 0.1136 - binary_crossentropy: 0.5381 - mean_squared_logarithmic_error: 0.1111\n",
      "Epoch 4/100\n",
      "10/10 [==============================] - 472s 47s/step - loss: 0.4927 - acc: 0.8062 - mean_squared_error: 0.1524 - logcosh: 0.0736 - kullback_leibler_divergence: 0.1276 - binary_crossentropy: 0.4927 - mean_squared_logarithmic_error: 0.0984\n",
      "Epoch 5/100\n",
      "10/10 [==============================] - 474s 47s/step - loss: 0.4645 - acc: 0.8693 - mean_squared_error: 0.1410 - logcosh: 0.0682 - kullback_leibler_divergence: 0.1351 - binary_crossentropy: 0.4645 - mean_squared_logarithmic_error: 0.0912\n",
      "Epoch 6/100\n",
      "10/10 [==============================] - 475s 47s/step - loss: 0.4429 - acc: 0.9058 - mean_squared_error: 0.1314 - logcosh: 0.0636 - kullback_leibler_divergence: 0.1313 - binary_crossentropy: 0.4429 - mean_squared_logarithmic_error: 0.0852\n",
      "Epoch 7/100\n",
      "10/10 [==============================] - 475s 47s/step - loss: 0.4206 - acc: 0.9102 - mean_squared_error: 0.1232 - logcosh: 0.0596 - kullback_leibler_divergence: 0.1345 - binary_crossentropy: 0.4206 - mean_squared_logarithmic_error: 0.0798\n",
      "Epoch 8/100\n",
      "10/10 [==============================] - 474s 47s/step - loss: 0.4009 - acc: 0.9104 - mean_squared_error: 0.1153 - logcosh: 0.0558 - kullback_leibler_divergence: 0.1340 - binary_crossentropy: 0.4009 - mean_squared_logarithmic_error: 0.0746\n",
      "Epoch 9/100\n",
      "10/10 [==============================] - 474s 47s/step - loss: 0.3833 - acc: 0.9164 - mean_squared_error: 0.1084 - logcosh: 0.0524 - kullback_leibler_divergence: 0.1380 - binary_crossentropy: 0.3833 - mean_squared_logarithmic_error: 0.0699\n",
      "Epoch 10/100\n",
      "10/10 [==============================] - 474s 47s/step - loss: 0.3644 - acc: 0.9218 - mean_squared_error: 0.1003 - logcosh: 0.0485 - kullback_leibler_divergence: 0.1352 - binary_crossentropy: 0.3644 - mean_squared_logarithmic_error: 0.0648\n",
      "Epoch 11/100\n",
      "10/10 [==============================] - 474s 47s/step - loss: 0.3464 - acc: 0.9245 - mean_squared_error: 0.0940 - logcosh: 0.0455 - kullback_leibler_divergence: 0.1339 - binary_crossentropy: 0.3464 - mean_squared_logarithmic_error: 0.0604\n",
      "Epoch 12/100\n",
      "10/10 [==============================] - 473s 47s/step - loss: 0.3304 - acc: 0.9276 - mean_squared_error: 0.0882 - logcosh: 0.0426 - kullback_leibler_divergence: 0.1314 - binary_crossentropy: 0.3304 - mean_squared_logarithmic_error: 0.0564\n",
      "Epoch 13/100\n",
      "10/10 [==============================] - 474s 47s/step - loss: 0.3179 - acc: 0.9288 - mean_squared_error: 0.0829 - logcosh: 0.0400 - kullback_leibler_divergence: 0.1382 - binary_crossentropy: 0.3179 - mean_squared_logarithmic_error: 0.0526\n",
      "Epoch 14/100\n",
      "10/10 [==============================] - 475s 47s/step - loss: 0.3010 - acc: 0.9281 - mean_squared_error: 0.0780 - logcosh: 0.0376 - kullback_leibler_divergence: 0.1248 - binary_crossentropy: 0.3010 - mean_squared_logarithmic_error: 0.0494\n",
      "Epoch 15/100\n",
      "10/10 [==============================] - 473s 47s/step - loss: 0.2891 - acc: 0.9311 - mean_squared_error: 0.0733 - logcosh: 0.0353 - kullback_leibler_divergence: 0.1280 - binary_crossentropy: 0.2891 - mean_squared_logarithmic_error: 0.0461\n",
      "Epoch 16/100\n",
      "10/10 [==============================] - 473s 47s/step - loss: 0.2750 - acc: 0.9327 - mean_squared_error: 0.0689 - logcosh: 0.0331 - kullback_leibler_divergence: 0.1278 - binary_crossentropy: 0.2750 - mean_squared_logarithmic_error: 0.0429\n",
      "Epoch 17/100\n",
      "10/10 [==============================] - 474s 47s/step - loss: 0.2622 - acc: 0.9347 - mean_squared_error: 0.0651 - logcosh: 0.0312 - kullback_leibler_divergence: 0.1252 - binary_crossentropy: 0.2622 - mean_squared_logarithmic_error: 0.0402\n",
      "Epoch 18/100\n",
      "10/10 [==============================] - 472s 47s/step - loss: 0.2508 - acc: 0.9362 - mean_squared_error: 0.0615 - logcosh: 0.0295 - kullback_leibler_divergence: 0.1244 - binary_crossentropy: 0.2508 - mean_squared_logarithmic_error: 0.0376\n",
      "Epoch 19/100\n",
      "10/10 [==============================] - 474s 47s/step - loss: 0.2383 - acc: 0.9392 - mean_squared_error: 0.0577 - logcosh: 0.0276 - kullback_leibler_divergence: 0.1221 - binary_crossentropy: 0.2383 - mean_squared_logarithmic_error: 0.0349\n",
      "Epoch 20/100\n",
      "10/10 [==============================] - 473s 47s/step - loss: 0.2288 - acc: 0.9402 - mean_squared_error: 0.0551 - logcosh: 0.0263 - kullback_leibler_divergence: 0.1227 - binary_crossentropy: 0.2288 - mean_squared_logarithmic_error: 0.0329\n",
      "Epoch 21/100\n",
      "10/10 [==============================] - 441s 44s/step - loss: 0.2157 - acc: 0.9438 - mean_squared_error: 0.0511 - logcosh: 0.0244 - kullback_leibler_divergence: 0.1145 - binary_crossentropy: 0.2157 - mean_squared_logarithmic_error: 0.0305\n",
      "Epoch 22/100\n",
      "10/10 [==============================] - 300s 30s/step - loss: 0.2067 - acc: 0.9462 - mean_squared_error: 0.0485 - logcosh: 0.0231 - kullback_leibler_divergence: 0.1146 - binary_crossentropy: 0.2067 - mean_squared_logarithmic_error: 0.0286\n",
      "Epoch 23/100\n",
      "10/10 [==============================] - 300s 30s/step - loss: 0.2029 - acc: 0.9449 - mean_squared_error: 0.0481 - logcosh: 0.0228 - kullback_leibler_divergence: 0.1214 - binary_crossentropy: 0.2029 - mean_squared_logarithmic_error: 0.0279\n",
      "Epoch 24/100\n",
      "10/10 [==============================] - 301s 30s/step - loss: 0.1917 - acc: 0.9488 - mean_squared_error: 0.0448 - logcosh: 0.0212 - kullback_leibler_divergence: 0.1155 - binary_crossentropy: 0.1917 - mean_squared_logarithmic_error: 0.0258\n",
      "Epoch 25/100\n",
      " 6/10 [=================>............] - ETA: 2:00 - loss: 0.1893 - acc: 0.9472 - mean_squared_error: 0.0447 - logcosh: 0.0211 - kullback_leibler_divergence: 0.1189 - binary_crossentropy: 0.1893 - mean_squared_logarithmic_error: 0.0254"
     ]
    }
   ],
   "source": [
    "model.fit_generator( my_data_gen(training_img_paths[\"x\"], training_img_paths[\"y\"], batch_size=12), \n",
    "                              epochs = 100, steps_per_epoch = 10, verbose = True, callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_im, pred_lab = load_imgs_parallel(test_img_paths, num_slices=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(x=ready_im, batch_size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visual_test_n_preds(5, ready_lab, preds, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
