{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brightness_range = [-60, 150]\n",
    "contrast_range =  [0.5,2]\n",
    "\n",
    "x = np.random.randint(0, 2)\n",
    "def get_image_slices(img):\n",
    "    \n",
    "    dim = 2560\n",
    "    imgs = np.zeros([4,640,640,3])\n",
    "    imgs[0] = img[0:int(dim/4), 0:int(dim/4), :]\n",
    "    imgs[1] = img[int(dim/4):int(dim/2), int(dim/4):int(dim/2), :]\n",
    "    imgs[2] = img[int(dim/2):int(3*dim/4), int(dim/2):int(3*dim/4), :]\n",
    "    imgs[3] = img[int(3*dim/4):int(dim), int(3*dim/4):int(dim), :]\n",
    "    \n",
    "    return np.asarray(imgs)\n",
    "\n",
    "def contrast_n_brightness(img_path, c_range=[0.5,2], b_range=[-60, 150]):\n",
    "    img = load_img(img_path)\n",
    "    def rand_generator(min= -2, max = 10):\n",
    "        n = (max-min)*np.random.random()+min\n",
    "        return n\n",
    "    x = np.random.randint(0, 2)\n",
    "    if x ==1:\n",
    "        contrast = rand_generator(c_range[0], c_range[1])\n",
    "        brightness = 0\n",
    "        \n",
    "    else:\n",
    "        contrast = 1\n",
    "        brightness = rand_generator(b_range[0], b_range[1])\n",
    "    img = np.multiply(img, contrast)+brightness\n",
    "    img = np.clip(img, 0, 255)\n",
    "    img = img/255\n",
    "    img = get_image_slices(img)\n",
    "    return img\n",
    "\n",
    "def load_img(path, norm = False):\n",
    "    if norm:\n",
    "        img =  cv2.imread(path)/255\n",
    "    else: \n",
    "        img = cv2.imread(path)\n",
    "    return img\n",
    "def my_data_gen(in_paths, out_paths, batch_size=32, img_dim = [640,640]):\n",
    "    \n",
    "    \n",
    "    #print(len(img_paths))\n",
    "    #print(img_paths.shape)\n",
    "    real_batch_Size = int(batch_size/4)\n",
    "\n",
    "    while True:\n",
    "        select_from = range(len(in_paths))\n",
    "        indices = np.random.choice(a=select_from, size = (real_batch_Size))\n",
    "    \n",
    "        in_paths = np.asarray(in_paths)\n",
    "        out_paths = np.asarray(out_paths)\n",
    "    \n",
    "        img_paths = in_paths[indices]\n",
    "        label_paths = out_paths[indices]\n",
    "    \n",
    "        loaded_imgs = np.zeros([0, 640, 640,1])\n",
    "        loaded_labels = np.zeros([0, 640, 640, 2])\n",
    "        for i in range(real_batch_Size):\n",
    "            img_temp = contrast_n_brightness(img_paths[i])\n",
    "            img_temp = img_temp[:, :, :, 0]\n",
    "            img_temp = img_temp.reshape(4, 640, 640, 1)\n",
    "            lbl_temp = load_img(label_paths[i], norm = True)\n",
    "            lbl_temp = get_image_slices(lbl_temp)\n",
    "            lbl_temp = lbl_temp[:, :, :, 0:2]\n",
    "            loaded_imgs = np.vstack([loaded_imgs, img_temp])\n",
    "            loaded_labels = np.vstack([loaded_labels, lbl_temp])\n",
    "        print(\"Batch loaded!\")\n",
    "        yield (loaded_imgs, loaded_labels)\n",
    "#test = my_data_gen(training_img_paths[\"x\"], training_img_paths[\"y\"], batch_size=32)\n",
    "#print(test[0].shape)\n",
    "#plt.imshow(test[0][0, :, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting some default values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_lib = \"x\"\n",
    "lab_lib = \"y\"\n",
    "\n",
    "num_training_images = 2600\n",
    "training_start_index = 0\n",
    "training_end_index = training_start_index+num_training_images\n",
    "\n",
    "test_starting_index = 2800\n",
    "num_test_images = 50\n",
    "test_end_index = test_starting_index+num_test_images\n",
    "\n",
    "img_paths = glob.glob(img_lib+\"/*.png\")\n",
    "lab_paths = glob.glob(lab_lib+\"/*.png\")\n",
    "\n",
    "img_num = len(img_paths)\n",
    "lab_num = len(lab_paths)\n",
    "message = \"The number of images found is {0:4d} and the number of labels is {1:4d}\".format(img_num, lab_num)\n",
    "print(message)\n",
    "\n",
    "#ensuring that they are in the same order:\n",
    "\n",
    "img_paths.sort()\n",
    "lab_paths.sort()\n",
    "\n",
    "#creating the dictionary with the selected slices of paths\n",
    "\n",
    "training_img_paths = {\"x\": img_paths[training_start_index:training_end_index], \"y\": lab_paths[training_start_index:training_end_index]}\n",
    "test_img_paths = {\"x\": img_paths[test_starting_index:test_end_index], \"y\": lab_paths[test_starting_index:test_end_index]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loading_helpers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tesing whether the images and labels match..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visual_test_n_loaded_imgs(5, ready_im, ready_lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from get_unet import *\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras import losses\n",
    "input_img = Input((640,640,1))\n",
    "model = get_unet(input_img, n_filters = 16, dropout = 0.5, batchnorm=True, passed_activation = \"sigmoid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_loss = losses.binary_crossentropy\n",
    "\n",
    "model.compile(\"adam\", loss=selected_loss, metrics=[\"accuracy\", losses.mean_squared_error, losses.logcosh, losses.kullback_leibler_divergence,  losses.binary_crossentropy, losses.mean_squared_logarithmic_error])\n",
    "\n",
    "#model.load_weights(\"./ckpts/2d_sigm_norm.hdf5\")\n",
    "\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\"./ckpts/sig_own_gen_1.hdf5\", save_best=1, monitor=\"val_loss\", mode=\"auto\")\n",
    "tboard = tf.keras.callbacks.TensorBoard(\"./ckpts/tb6/\", histogram_freq=1, batch_size=20, write_graph = False, write_grads = False, write_images = True, update_freq = \"epoch\")\n",
    "callbacks = [checkpoint, tboard]\n",
    "\n",
    "#datagen = tf.keras.preprocessing.image.ImageDataGenerator(validation_split=0.2, brightness_range=[0.3, 2])#,\n",
    "                               #rotation_range=15,\n",
    "                               #width_shift_range=0.1,\n",
    "                               #height_shift_range=0.1,\n",
    "                               #shear_range=0.01,\n",
    "                               #zoom_range=[0.5, 1.25],\n",
    "                               #horizontal_flip=True,\n",
    "                               #vertical_flip=True,\n",
    "                               #fill_mode='reflect',\n",
    "                               #rotation_range=360, fill_mode = \"reflect\", horizontal_flip=1, vertical_flip=1,)\n",
    "#datagen = tf.keras.preprocessing.image.ImageDataGenerator(featurewise_std_normalization= 1, rotation_range=360, fill_mode = \"reflect\", horizontal_flip=1, vertical_flip=1, validation_split=0.2)\n",
    "#you have to use datagen.fit if u want to use featurewise_std_normalization so that the generator learns about the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator( my_data_gen(training_img_paths[\"x\"], training_img_paths[\"y\"], batch_size=12), \n",
    "                              epochs = 100, steps_per_epoch = 10, verbose = True, callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_im, pred_lab = load_imgs_parallel(test_img_paths, num_slices=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(x=ready_im, batch_size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visual_test_n_preds(5, ready_lab, preds, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
