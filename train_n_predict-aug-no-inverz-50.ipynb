{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting some default values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of images found is 3000 and the number of labels is 3000\n"
     ]
    }
   ],
   "source": [
    "img_lib = \"x\"\n",
    "lab_lib = \"y\"\n",
    "\n",
    "num_training_images = 300\n",
    "training_start_index = 1500\n",
    "training_end_index = training_start_index+num_training_images\n",
    "\n",
    "test_starting_index = 2800\n",
    "num_test_images = 50\n",
    "test_end_index = test_starting_index+num_test_images\n",
    "\n",
    "img_paths = glob.glob(img_lib+\"/*.png\")\n",
    "lab_paths = glob.glob(lab_lib+\"/*.png\")\n",
    "\n",
    "img_num = len(img_paths)\n",
    "lab_num = len(lab_paths)\n",
    "message = \"The number of images found is {0:4d} and the number of labels is {1:4d}\".format(img_num, lab_num)\n",
    "print(message)\n",
    "\n",
    "#ensuring that they are in the same order:\n",
    "\n",
    "img_paths.sort()\n",
    "lab_paths.sort()\n",
    "\n",
    "#creating the dictionary with the selected slices of paths\n",
    "\n",
    "training_img_paths = {\"x\": img_paths[training_start_index:training_end_index], \"y\": lab_paths[training_start_index:training_end_index]}\n",
    "test_img_paths = {\"x\": img_paths[test_starting_index:test_end_index], \"y\": lab_paths[test_starting_index:test_end_index]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loading_helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 300 images has started.\n",
      "feed array's shape:(300, 2)\n",
      "   1 slice is being processed out of   20 slice.\n",
      "(2, 60, 640, 640, 3)\n",
      "   2 slice is being processed out of   20 slice.\n",
      "(2, 60, 640, 640, 3)\n",
      "   3 slice is being processed out of   20 slice.\n",
      "(2, 60, 640, 640, 3)\n",
      "   4 slice is being processed out of   20 slice.\n",
      "(2, 60, 640, 640, 3)\n",
      "   5 slice is being processed out of   20 slice.\n",
      "(2, 60, 640, 640, 3)\n",
      "   6 slice is being processed out of   20 slice.\n",
      "(2, 60, 640, 640, 3)\n",
      "   7 slice is being processed out of   20 slice.\n",
      "(2, 60, 640, 640, 3)\n",
      "   8 slice is being processed out of   20 slice.\n",
      "(2, 60, 640, 640, 3)\n",
      "   9 slice is being processed out of   20 slice.\n",
      "(2, 60, 640, 640, 3)\n",
      "  10 slice is being processed out of   20 slice.\n",
      "(2, 60, 640, 640, 3)\n",
      "  11 slice is being processed out of   20 slice.\n",
      "(2, 60, 640, 640, 3)\n",
      "  12 slice is being processed out of   20 slice.\n",
      "(2, 60, 640, 640, 3)\n",
      "  13 slice is being processed out of   20 slice.\n",
      "(2, 60, 640, 640, 3)\n",
      "  14 slice is being processed out of   20 slice.\n",
      "(2, 60, 640, 640, 3)\n",
      "  15 slice is being processed out of   20 slice.\n",
      "(2, 60, 640, 640, 3)\n",
      "  16 slice is being processed out of   20 slice.\n",
      "(2, 60, 640, 640, 3)\n",
      "  17 slice is being processed out of   20 slice.\n",
      "(2, 60, 640, 640, 3)\n",
      "  18 slice is being processed out of   20 slice.\n",
      "(2, 60, 640, 640, 3)\n",
      "  19 slice is being processed out of   20 slice.\n",
      "(2, 60, 640, 640, 3)\n",
      "  20 slice is being processed out of   20 slice.\n",
      "(2, 60, 640, 640, 3)\n",
      "Loading the images has taken 181 seconds.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "print(\"Loading %d images has started.\"%(num_training_images))\n",
    "start_time = time.time()\n",
    "ready_im, ready_lab = load_imgs_parallel(training_img_paths, num_slices=20)\n",
    "end_time= time.time()\n",
    "print(\"Loading the images has taken %d seconds.\"%(end_time-start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tesing whether the images and labels match..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visual_test_n_loaded_imgs(5, ready_im, ready_lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0722 22:23:18.254234 139829090731392 deprecation_wrapper.py:119] From /home/contact_gergo_endresz/j/get_unet.py:2: The name tf.keras.layers.CuDNNGRU is deprecated. Please use tf.compat.v1.keras.layers.CuDNNGRU instead.\n",
      "\n",
      "W0722 22:23:18.255571 139829090731392 deprecation_wrapper.py:119] From /home/contact_gergo_endresz/j/get_unet.py:2: The name tf.keras.layers.CuDNNLSTM is deprecated. Please use tf.compat.v1.keras.layers.CuDNNLSTM instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0722 22:23:19.067826 139829090731392 deprecation.py:506] From /home/contact_gergo_endresz/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "from get_unet import *\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras import losses\n",
    "input_img = Input((640,640,1))\n",
    "model = get_unet(input_img, n_filters = 16, dropout = 0.5, batchnorm=True, passed_activation = \"sigmoid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0722 22:23:20.109578 139829090731392 deprecation.py:323] From /home/contact_gergo_endresz/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "selected_loss = losses.binary_crossentropy\n",
    "\n",
    "model.compile(\"adam\", loss=selected_loss, metrics=[\"accuracy\", losses.mean_squared_error, losses.logcosh, losses.kullback_leibler_divergence,  losses.binary_crossentropy, losses.mean_squared_logarithmic_error])\n",
    "\n",
    "#model.load_weights(\"./ckpts/2d_sigm_norm.hdf5\")\n",
    "\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\"./ckpts/2d_sigm_norm_br1.hdf5\", save_best=1, monitor=\"val_loss\", mode=\"auto\")\n",
    "tboard = tf.keras.callbacks.TensorBoard(\"./ckpts/tb3/\", histogram_freq=1, batch_size=20, write_graph = False, write_grads = False, write_images = True, update_freq = \"epoch\")\n",
    "callbacks = [checkpoint, tboard]\n",
    "\n",
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(validation_split=0.2, brightness_range=[0.3, 2])#,\n",
    "                               #rotation_range=15,\n",
    "                               #width_shift_range=0.1,\n",
    "                               #height_shift_range=0.1,\n",
    "                               #shear_range=0.01,\n",
    "                               #zoom_range=[0.5, 1.25],\n",
    "                               #horizontal_flip=True,\n",
    "                               #vertical_flip=True,\n",
    "                               #fill_mode='reflect',\n",
    "                               #rotation_range=360, fill_mode = \"reflect\", horizontal_flip=1, vertical_flip=1,)\n",
    "#datagen = tf.keras.preprocessing.image.ImageDataGenerator(featurewise_std_normalization= 1, rotation_range=360, fill_mode = \"reflect\", horizontal_flip=1, vertical_flip=1, validation_split=0.2)\n",
    "#you have to use datagen.fit if u want to use featurewise_std_normalization so that the generator learns about the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    }
   ],
   "source": [
    "model.fit_generator(datagen.flow(x=ready_im, y=ready_lab , batch_size = 20, shuffle=True), steps_per_epoch = 10, epochs = 100,verbose = True, callbacks = callbacks, use_multiprocessing = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_im, pred_lab = load_imgs_parallel(test_img_paths, num_slices=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(x=ready_im, batch_size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visual_test_n_preds(5, ready_lab, preds, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
