{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "brightness_range = [-60, 150]\n",
    "contrast_range =  [0.5,2]\n",
    "\n",
    "x = np.random.randint(0, 2)\n",
    "def get_image_slices(img):\n",
    "    \n",
    "    dim = 2560\n",
    "    imgs = np.zeros([4,640,640,3])\n",
    "    imgs[0] = img[0:int(dim/4), 0:int(dim/4), :]\n",
    "    imgs[1] = img[int(dim/4):int(dim/2), int(dim/4):int(dim/2), :]\n",
    "    imgs[2] = img[int(dim/2):int(3*dim/4), int(dim/2):int(3*dim/4), :]\n",
    "    imgs[3] = img[int(3*dim/4):int(dim), int(3*dim/4):int(dim), :]\n",
    "    \n",
    "    return np.asarray(imgs)\n",
    "\n",
    "def contrast_n_brightness(img_path, c_range=[0.5,2], b_range=[-60, 150]):\n",
    "    img = load_img(img_path)\n",
    "    def rand_generator(min= -2, max = 10):\n",
    "        n = (max-min)*np.random.random()+min\n",
    "        return n\n",
    "    x = np.random.randint(0, 2)\n",
    "    if x ==1:\n",
    "        contrast = rand_generator(c_range[0], c_range[1])\n",
    "        brightness = 0\n",
    "        \n",
    "    else:\n",
    "        contrast = 1\n",
    "        brightness = rand_generator(b_range[0], b_range[1])\n",
    "    img = np.multiply(img, contrast)+brightness\n",
    "    img = np.clip(img, 0, 255)\n",
    "    img = img/255\n",
    "    img = get_image_slices(img)\n",
    "    return img\n",
    "\n",
    "def load_img(path, norm = False):\n",
    "    if norm:\n",
    "        img =  cv2.imread(path)/255\n",
    "    else: \n",
    "        img = cv2.imread(path)\n",
    "    return img\n",
    "def my_data_gen(in_paths, out_paths, batch_size=32, img_dim = [640,640]):\n",
    "    \n",
    "    \n",
    "    #print(len(img_paths))\n",
    "    #print(img_paths.shape)\n",
    "    real_batch_Size = int(batch_size/4)\n",
    "\n",
    "    while True:\n",
    "        select_from = range(len(in_paths))\n",
    "        indices = np.random.choice(a=select_from, size = (real_batch_Size))\n",
    "    \n",
    "        in_paths = np.asarray(in_paths)\n",
    "        out_paths = np.asarray(out_paths)\n",
    "    \n",
    "        img_paths = in_paths[indices]\n",
    "        label_paths = out_paths[indices]\n",
    "    \n",
    "        loaded_imgs = np.zeros([0, 640, 640,1])\n",
    "        loaded_labels = np.zeros([0, 640, 640, 2])\n",
    "        for i in range(real_batch_Size):\n",
    "            print(i)\n",
    "            img_temp = contrast_n_brightness(img_paths[i])\n",
    "            img_temp = img_temp[:, :, :, 0]\n",
    "            img_temp = img_temp.reshape(4, 640, 640, 1)\n",
    "            lbl_temp = load_img(label_paths[i], norm = True)\n",
    "            lbl_temp = get_image_slices(lbl_temp)\n",
    "            lbl_temp = lbl_temp[:, :, :, 0:2]\n",
    "            loaded_imgs = np.vstack([loaded_imgs, img_temp])\n",
    "            loaded_labels = np.vstack([loaded_labels, lbl_temp])\n",
    "        yield (loaded_imgs, loaded_labels)\n",
    "#test = my_data_gen(training_img_paths[\"x\"], training_img_paths[\"y\"], batch_size=32)\n",
    "#print(test[0].shape)\n",
    "#plt.imshow(test[0][0, :, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting some default values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of images found is 3000 and the number of labels is 3000\n"
     ]
    }
   ],
   "source": [
    "img_lib = \"x\"\n",
    "lab_lib = \"y\"\n",
    "\n",
    "num_training_images = 2600\n",
    "training_start_index = 0\n",
    "training_end_index = training_start_index+num_training_images\n",
    "\n",
    "test_starting_index = 2800\n",
    "num_test_images = 50\n",
    "test_end_index = test_starting_index+num_test_images\n",
    "\n",
    "img_paths = glob.glob(img_lib+\"/*.png\")\n",
    "lab_paths = glob.glob(lab_lib+\"/*.png\")\n",
    "\n",
    "img_num = len(img_paths)\n",
    "lab_num = len(lab_paths)\n",
    "message = \"The number of images found is {0:4d} and the number of labels is {1:4d}\".format(img_num, lab_num)\n",
    "print(message)\n",
    "\n",
    "#ensuring that they are in the same order:\n",
    "\n",
    "img_paths.sort()\n",
    "lab_paths.sort()\n",
    "\n",
    "#creating the dictionary with the selected slices of paths\n",
    "\n",
    "training_img_paths = {\"x\": img_paths[training_start_index:training_end_index], \"y\": lab_paths[training_start_index:training_end_index]}\n",
    "test_img_paths = {\"x\": img_paths[test_starting_index:test_end_index], \"y\": lab_paths[test_starting_index:test_end_index]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loading_helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 600 images has started\n",
      "feed array's shape:(600, 2)\n",
      "   1 slice is being processed out of   20 slice.\n",
      "(2, 120, 640, 640, 3)\n",
      "   2 slice is being processed out of   20 slice.\n",
      "(2, 120, 640, 640, 3)\n",
      "   3 slice is being processed out of   20 slice.\n",
      "(2, 120, 640, 640, 3)\n",
      "   4 slice is being processed out of   20 slice.\n",
      "(2, 120, 640, 640, 3)\n",
      "   5 slice is being processed out of   20 slice.\n",
      "(2, 120, 640, 640, 3)\n",
      "   6 slice is being processed out of   20 slice.\n",
      "(2, 120, 640, 640, 3)\n",
      "   7 slice is being processed out of   20 slice.\n",
      "(2, 120, 640, 640, 3)\n",
      "   8 slice is being processed out of   20 slice.\n",
      "(2, 120, 640, 640, 3)\n",
      "   9 slice is being processed out of   20 slice.\n",
      "(2, 120, 640, 640, 3)\n",
      "  10 slice is being processed out of   20 slice.\n",
      "(2, 120, 640, 640, 3)\n",
      "  11 slice is being processed out of   20 slice.\n",
      "(2, 120, 640, 640, 3)\n",
      "  12 slice is being processed out of   20 slice.\n",
      "(2, 120, 640, 640, 3)\n",
      "  13 slice is being processed out of   20 slice.\n",
      "(2, 120, 640, 640, 3)\n",
      "  14 slice is being processed out of   20 slice.\n",
      "(2, 120, 640, 640, 3)\n",
      "  15 slice is being processed out of   20 slice.\n",
      "(2, 120, 640, 640, 3)\n",
      "  16 slice is being processed out of   20 slice.\n",
      "(2, 120, 640, 640, 3)\n",
      "  17 slice is being processed out of   20 slice.\n",
      "(2, 120, 640, 640, 3)\n",
      "  18 slice is being processed out of   20 slice.\n",
      "(2, 120, 640, 640, 3)\n",
      "  19 slice is being processed out of   20 slice.\n",
      "(2, 120, 640, 640, 3)\n",
      "  20 slice is being processed out of   20 slice.\n",
      "(2, 120, 640, 640, 3)\n",
      "Loading the images has taken 288 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "print(\"Loading %d images has started\"%(num_training_images))\n",
    "start_time = time.time()\n",
    "ready_im, ready_lab = load_imgs_parallel(training_img_paths, num_slices=20)\n",
    "end_time= time.time()\n",
    "print(\"Loading the images has taken %d seconds\"%(end_time-start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tesing whether the images and labels match..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visual_test_n_loaded_imgs(5, ready_im, ready_lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0722 22:30:00.084130 140472044377472 deprecation_wrapper.py:119] From /home/contact_gergo_endresz/j/get_unet.py:2: The name tf.keras.layers.CuDNNGRU is deprecated. Please use tf.compat.v1.keras.layers.CuDNNGRU instead.\n",
      "\n",
      "W0722 22:30:00.085690 140472044377472 deprecation_wrapper.py:119] From /home/contact_gergo_endresz/j/get_unet.py:2: The name tf.keras.layers.CuDNNLSTM is deprecated. Please use tf.compat.v1.keras.layers.CuDNNLSTM instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0722 22:30:01.050250 140472044377472 deprecation.py:506] From /home/contact_gergo_endresz/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "from get_unet import *\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras import losses\n",
    "input_img = Input((640,640,1))\n",
    "model = get_unet(input_img, n_filters = 16, dropout = 0.5, batchnorm=True, passed_activation = \"softmax\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_loss = losses.binary_crossentropy\n",
    "\n",
    "model.compile(\"adam\", loss=selected_loss, metrics=[\"accuracy\", losses.mean_squared_error, losses.logcosh, losses.kullback_leibler_divergence,  losses.binary_crossentropy, losses.mean_squared_logarithmic_error])\n",
    "\n",
    "#model.load_weights(\"./ckpts/2d_sigm_norm.hdf5\")\n",
    "\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\"./ckpts/2d_sm_norm_br1.hdf5\", save_best=1, monitor=\"val_loss\", mode=\"auto\")\n",
    "tboard = tf.keras.callbacks.TensorBoard(\"./ckpts/tb4/\", histogram_freq=1, batch_size=20, write_graph = False, write_grads = False, write_images = True, update_freq = \"epoch\")\n",
    "callbacks = [checkpoint, tboard]\n",
    "\n",
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(validation_split=0.2, brightness_range=[0.3, 2])#,\n",
    "                               #rotation_range=15,\n",
    "                               #width_shift_range=0.1,\n",
    "                               #height_shift_range=0.1,\n",
    "                               #shear_range=0.01,\n",
    "                               #zoom_range=[0.5, 1.25],\n",
    "                               #horizontal_flip=True,\n",
    "                               #vertical_flip=True,\n",
    "                               #fill_mode='reflect',\n",
    "                               #rotation_range=360, fill_mode = \"reflect\", horizontal_flip=1, vertical_flip=1,)\n",
    "#datagen = tf.keras.preprocessing.image.ImageDataGenerator(featurewise_std_normalization= 1, rotation_range=360, fill_mode = \"reflect\", horizontal_flip=1, vertical_flip=1, validation_split=0.2)\n",
    "#you have to use datagen.fit if u want to use featurewise_std_normalization so that the generator learns about the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0722 22:30:08.218767 140472044377472 deprecation.py:323] From /home/contact_gergo_endresz/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "10/10 [==============================] - 256s 26s/step - loss: 0.7823 - acc: 0.4755 - mean_squared_error: 0.2821 - logcosh: 0.1331 - kullback_leibler_divergence: 0.1397 - binary_crossentropy: 0.7823 - mean_squared_logarithmic_error: 0.1686\n",
      "Epoch 2/100\n",
      "10/10 [==============================] - 244s 24s/step - loss: 0.7008 - acc: 0.5274 - mean_squared_error: 0.2527 - logcosh: 0.1209 - kullback_leibler_divergence: 0.1046 - binary_crossentropy: 0.7008 - mean_squared_logarithmic_error: 0.1580\n",
      "Epoch 3/100\n",
      " 5/10 [==============>...............] - ETA: 2:01 - loss: 0.6873 - acc: 0.5688 - mean_squared_error: 0.2467 - logcosh: 0.1182 - kullback_leibler_divergence: 0.1037 - binary_crossentropy: 0.6873 - mean_squared_logarithmic_error: 0.1547"
     ]
    }
   ],
   "source": [
    "model.fit_generator(datagen.flow(x=ready_im, y=ready_lab , batch_size = 10, shuffle=True), steps_per_epoch = 10, epochs = 100,verbose = True, callbacks = callbacks, use_multiprocessing = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_im, pred_lab = load_imgs_parallel(test_img_paths, num_slices=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(x=ready_im, batch_size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visual_test_n_preds(5, ready_lab, preds, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
